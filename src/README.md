Arquitectura de Notificaciones Resilientes
üìå Descripci√≥n General

Este proyecto implementa el n√∫cleo de un motor de notificaciones resiliente, dise√±ado para funcionar in-memory, pero preparado para escalar a proveedores externos como Redis o bases de datos SQL sin modificar la l√≥gica de negocio.

El sistema soporta:

M√∫ltiples proveedores de notificaci√≥n

Failover autom√°tico

Rate limiting por usuario

Priorizaci√≥n de mensajes

Cache con TTL

Arquitectura extensible y desacoplada

üß± Arquitectura General

El dise√±o sigue principios de Clean Architecture y SOLID, separando claramente:

Domain: contratos y reglas de negocio

Application: orquestaci√≥n del flujo

Infrastructure: implementaciones concretas (providers, cache, rate limiter)

Las dependencias siempre apuntan hacia abstracciones, no implementaciones concretas.

üîå ¬øC√≥mo se garantiza el principio Open/Closed?

El sistema garantiza el principio Open/Closed (abierto para extensi√≥n, cerrado para modificaci√≥n) mediante el uso del Strategy Pattern.

üîπ Ejemplo: Agregar un nuevo canal (WhatsApp)

Se crea una nueva implementaci√≥n de la interfaz INotificationProvider:

class WhatsAppProvider implements INotificationProvider {
async send(notification: Notification): Promise<void> {
// l√≥gica de env√≠o
}
}

El nuevo provider se inyecta en el NotificationManager:

new NotificationManager(
[new SendGridProvider(), new WhatsAppProvider()],
rateLimiter,
cache
);

‚úÖ Resultado

No se modifica el NotificationManager

No se altera la l√≥gica de negocio

No se rompen dependencias existentes

Esto permite agregar nuevos canales (Email, SMS, WhatsApp, Push, etc.) sin tocar el core del sistema.
//
üß© Cumplimiento de Principios SOLID
S ‚Äî Single Responsibility Principle (SRP)

Cada clase tiene una √∫nica responsabilidad:

NotificationManager: orquesta el flujo de env√≠o (rate limit, cache, failover).

SendGridMockProvider, TwilioMockProvider: encapsulan la l√≥gica de env√≠o de cada proveedor.

InMemoryRateLimiter: controla el rate limiting por usuario.

InMemoryCache: gestiona almacenamiento temporal y expiraci√≥n (TTL).

Esto permite modificar o extender cada componente sin afectar a los dem√°s.

O ‚Äî Open/Closed Principle (OCP)

El sistema est√° abierto a extensi√≥n y cerrado a modificaci√≥n.

Nuevos canales de notificaci√≥n se agregan implementando INotificationProvider.

Nuevas estrategias de cache o rate limiting se agregan implementando ICache o IRateLimiter.

El core (NotificationManager) no necesita cambios para soportar nuevas funcionalidades.

L ‚Äî Liskov Substitution Principle (LSP)

Todas las implementaciones pueden sustituirse por sus interfaces sin alterar el comportamiento del sistema.

Cualquier implementaci√≥n de INotificationProvider puede reemplazar a otra.

InMemoryCache puede ser reemplazado por RedisCache.

InMemoryRateLimiter puede ser reemplazado por una versi√≥n distribuida.

El sistema funciona correctamente independientemente de la implementaci√≥n concreta.

I ‚Äî Interface Segregation Principle (ISP)

Las interfaces est√°n espec√≠ficamente definidas y no fuerzan dependencias innecesarias:

INotificationProvider expone solo el m√©todo send.

ICache expone √∫nicamente operaciones de cache.

IRateLimiter se enfoca solo en control de env√≠os.

Esto mantiene las implementaciones simples y cohesionadas.

D ‚Äî Dependency Inversion Principle (DIP)

El core del sistema depende de abstracciones, no de implementaciones concretas.

NotificationManager depende de INotificationProvider, IRateLimiter y ICache.

Las implementaciones concretas se inyectan desde el entry point.

Esto permite:

cambiar infraestructura sin afectar la l√≥gica

facilitar testing

escalar a Redis u otros servicios externos
//
üîÅ ¬øC√≥mo se maneja la concurrencia?
Problema

¬øQu√© ocurre si dos procesos intentan notificar al mismo usuario al mismo tiempo?

Soluci√≥n

Rate Limiting por usuario
Antes de enviar una notificaci√≥n, el sistema valida si el usuario puede recibir mensajes dentro de una ventana de tiempo configurable.

Cache con TTL (Time To Live)
Se utiliza un servicio de cache (ICache) para evitar env√≠os duplicados:

Si una notificaci√≥n ya fue enviada recientemente, se bloquea el reenv√≠o.

El TTL garantiza expiraci√≥n autom√°tica del estado.

Dise√±o escalable

En entornos locales se usa InMemoryCache

En producci√≥n, la misma interfaz permite reemplazarlo por Redis, habilitando:

locks distribuidos

atomicidad

consistencia entre procesos

üìå Nota sobre entornos serverless

En plataformas como Netlify Functions, el cache in-memory no persiste entre invocaciones.
Este comportamiento es esperado y justifica el uso de Redis en escenarios reales.

üß™ Testing

El proyecto incluye tests unitarios que validan:

Rate limiting por usuario

Failover entre proveedores

Expiraci√≥n de cache por TTL

Evita env√≠os duplicados

Los tests prueban comportamiento, no implementaci√≥n, asegurando estabilidad ante cambios futuros.

üöÄ Escalabilidad

Gracias al uso de interfaces (INotificationProvider, IRateLimiter, ICache), el sistema puede evolucionar f√°cilmente hacia:

Redis para cache distribuido

Bases de datos SQL para persistencia

Nuevos canales de comunicaci√≥n

Ejecuci√≥n en entornos distribuidos

Todo esto sin modificar la l√≥gica central.

‚úÖ Conclusi√≥n

Este dise√±o prioriza:

Extensibilidad

Resiliencia

Claridad de responsabilidades

Preparaci√≥n para producci√≥n

El n√∫cleo del sistema permanece estable mientras las capacidades del sistema pueden crecer de forma controlada.
